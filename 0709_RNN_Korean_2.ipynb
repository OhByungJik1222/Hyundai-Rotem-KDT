{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어를 이용한 감성 분류\n",
    "# 이진분류 문제 => 리뷰내용이 긍정인지 부정인지 학습한 후 예측!\n",
    "# 기존에 배웠던 Token, Tokenizer, Padding,  vacabulary, One-Hot, Embedding\n",
    "# 이런 개념들이 어떻게 사용되는지 코드로 확인해 보면 될 듯 해요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ee83200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 module부터 불러와요!\n",
    "%reset -f\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d6ff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14628807/14628807\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4814/942972367.py:2: UserWarning: Could not extract archive.\n",
      "  train_file = tf.keras.utils.get_file(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 네이버에서 제공하는 네이버 영화 리뷰 데이터셋을 다운로드해요.\n",
    "train_file = tf.keras.utils.get_file(\n",
    "    cache_dir='./data', # 다운로드 경로\n",
    "    fname='ratings_train.txt',\n",
    "    origin='http://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt',\n",
    "    extract=True\n",
    ")\n",
    "\n",
    "train_path = os.path.join('./data/datasets', 'ratings_train.txt')\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "display(train_df) # 리뷰 개수가 15만개에요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81457f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n",
      "\u001b[1m4893335/4893335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4814/2378423992.py:2: UserWarning: Could not extract archive.\n",
      "  test_file = tf.keras.utils.get_file(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>4608761</td>\n",
       "      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>5308387</td>\n",
       "      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9072549</td>\n",
       "      <td>그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>5802125</td>\n",
       "      <td>절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>6070594</td>\n",
       "      <td>마무리는 또 왜이래</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           document  label\n",
       "0      6270596                                                굳 ㅋ      1\n",
       "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
       "...        ...                                                ...    ...\n",
       "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
       "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
       "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
       "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
       "49999  6070594                                         마무리는 또 왜이래      0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 네이버에서 제공하는 네이버 영화 리뷰 데이터셋을 다운로드해요.\n",
    "test_file = tf.keras.utils.get_file(\n",
    "    cache_dir='./data', # 다운로드 경로\n",
    "    fname='ratings_test.txt',\n",
    "    origin='http://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt',\n",
    "    extract=True\n",
    ")\n",
    "\n",
    "test_path = os.path.join('./data/datasets', 'ratings_test.txt')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "display(test_df) # 테스트용 리뷰 개수가 5만개에요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997620b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    75173\n",
      "1    74827\n",
      "Name: count, dtype: int64\n",
      "id          0\n",
      "document    5\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 간단하게 데이터 특성에 대해서 알아보아요!\n",
    "# 이진분류를 하고 있기 때문에 적어도 긍정과 부정이 1:1 비율로 있어야\n",
    "# 학습이 잘 이루어질 것 같아요!\n",
    "cnt = train_df['label'].value_counts()\n",
    "print(cnt) # 데이터 불균형 문제는 없을 것 같아요!\n",
    "\n",
    "print(train_df.isnull().sum()) # 결측치가 5개가 있어요.\n",
    "                               # 삭제를 해야할 것 같아요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8dabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token을 구별해서 이 Token으로 vocabulary를 구성해야 해요!\n",
    "# 그런데 한국어는 이 Token을 분리해 내는 작업 자체가 어려워요!\n",
    "# => 형태소 분석으로\n",
    "# 형태소 분석은 어떻게 하면 되나요?\n",
    "# => 라이브러리가 있어요!\n",
    "# 그럼 가장 많이 사용되는 형태소 분석기는 어떤 것들이 있나요?\n",
    "# 1. Mecab - 가장 널리 사용되요! C++기반 빠르고 정확해요. 실무에서 주로 사용.\n",
    "#            설치가 약간 복잡.\n",
    "# 2. Okt(Open Korean Text Processor) - 학습용으로 사용되요! 설치가 간단.\n",
    "# 3. Kiwi - 딥러닝 기반으로 띄어쓰기 오류에 강해요!\n",
    "\n",
    "# 우리는 Mecab을 설치해서 사용할 거에요!\n",
    "# Ubuntu Linux에 설치하는 과정\n",
    "\n",
    "# 필요한 package 설치\n",
    "# sudo apt update\n",
    "# sudo apt install -y make curl git build-essential autoconf automake libtool\n",
    "\n",
    "# Mecab 설치\n",
    "# sudo apt install -y mecab libmecab-dev mecab-ipadic-utf8\n",
    "\n",
    "# mecab-ko-dic 다운로드\n",
    "# cd /tmp\n",
    "# wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
    "# tar zxfv mecab-ko-dic-2.1.1-20180720.tar.gz\n",
    "# cd mecab-ko-dic-2.1.1-20180720\n",
    "\n",
    "# 사전 컴파일 및 설치\n",
    "# ./autogen.sh\n",
    "# ./configure\n",
    "# make\n",
    "# sudo make install\n",
    "\n",
    "# 설치 경로 확인\n",
    "# mecab-config --dicdir\n",
    "\n",
    "# 설정파일 확인\n",
    "# sudo vi /usr/local/etc/mecabrc\n",
    "\n",
    "# 이때 Vim에서 해당 내용 수정\n",
    "'''\n",
    "dicdir = /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic -> 확인한 경로로 수정\n",
    "userdic =\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d85214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab 설치가 다 되었으면 -> 확인을 한 후에\n",
    "# 이 Mecab을 Python에서 사용할거에요!\n",
    "# 이 작업을 수행해 줄 Python module을 설치해야 해요!\n",
    "# pip install mecab-python3\n",
    "# pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2e2c708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이', '것', '은', '소리', '없는', '아우성', '.', '저', '푸른', '해원', '을', '향', '하여', '흔드는', '노스', '텔', '지', '어의', '손수건']\n",
      "['이것', '은', '소리', '없', '는', '아우성', '.', '저', '푸른', '해원', '을', '향하', '여', '흔드', '는', '노', '스텔', '지어', '의', '손수건']\n"
     ]
    }
   ],
   "source": [
    "# 코드상에서 형태소 분석을 해 보아요!\n",
    "from konlpy.tag import Mecab, Okt\n",
    "\n",
    "dicpath='/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic'\n",
    "\n",
    "okt = Okt()\n",
    "mecab = Mecab(dicpath=dicpath)\n",
    "\n",
    "text = '이것은 소리없는 아우성. 저 푸른 해원을 향하여 흔드는 노스텔지어의 손수건'\n",
    "\n",
    "print(okt.morphs(text))\n",
    "print(mecab.morphs(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0b823a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65483/3779165594.py:12: UserWarning: Could not extract archive.\n",
      "  train_file = tf.keras.utils.get_file(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65483/3779165594.py:22: UserWarning: Could not extract archive.\n",
      "  test_file = tf.keras.utils.get_file(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그럼 처음부터 데이터 전처리까지 순차적으로 한번 코드작업을 수행해 보아요!\n",
    "%reset -f\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "# 네이버에서 제공하는 네이버 영화 리뷰 데이터셋을 다운로드 해요.\n",
    "train_file = tf.keras.utils.get_file(\n",
    "    cache_dir='./data', # 다운로드 경로\n",
    "    fname='ratings_train.txt', # 파일명\n",
    "    origin='https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt',\n",
    "    extract=True\n",
    ")\n",
    "train_path = os.path.join('./data/datasets', 'ratings_train.txt')\n",
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "display(train_df.head())\n",
    "\n",
    "test_file = tf.keras.utils.get_file(\n",
    "    cache_dir='./data',   # 다운로드 경로\n",
    "    fname='ratings_test.txt',  # 파일명\n",
    "    origin='https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt',\n",
    "    extract=True\n",
    ")\n",
    "test_path = os.path.join('./data/datasets', 'ratings_test.txt')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59800293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. 데이터를 가져왔으니 이제 영어, 한글, 띄어쓰기(공백)만 남기고 나머지\n",
    "#    특수문자를 제거 => 정규식을 이용해서 처리\n",
    "train_df['document'] = train_df['document'].str.replace(r'[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ ]',\n",
    "                                                        '',\n",
    "                                                        regex=True)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07cf01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149995, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/149995 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 149995/149995 [00:07<00:00, 19855.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                     [빙, 짜증, 네요, 목소리]\n",
       "1    [흠, 포스터, 보고, 초딩, 영화, 줄, 오버, 연기, 조차, 가볍, 지, 않, 구나]\n",
       "2                                  [재, 밓었다그래서보는것을추천한다]\n",
       "3                [교도소, 이야기, 구먼, 솔직히, 재미, 없, 다, 평점, 조정]\n",
       "4    [사이몬페그, 의, 익살, 스런, 연기, 돋보였, 던, 영화, 스파이더맨, 늙, 보...\n",
       "Name: document, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. 결측치 5개 제거\n",
    "train_df = train_df.dropna()\n",
    "print(train_df.shape)\n",
    "\n",
    "# 3. 불용어(stopword) 제거\n",
    "#    관사, 전치사, 조사, 접속사 => 의미가 없는 단어를 지칭\n",
    "#    한국어에는 정말 많은 불용어가 존재하는데 이 중 일부만 제거\n",
    "#    불용어를 제거하는 함수를 이용해서 처리\n",
    "\n",
    "from konlpy.tag import Okt, Mecab\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas() # tqdm을 pandas에 부착(pandas의 dataframe을 처리할 때 progressbar 표시)\n",
    "\n",
    "dicpath='/usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ko-dic'\n",
    "mecab = Mecab(dicpath=dicpath)\n",
    "# okt = Okt()\n",
    "\n",
    "# 형태소 분석 후 불용어를 제거해서 그 결과를 리턴하는 함수\n",
    "def word_tokenization(text):\n",
    "\n",
    "    stop_words = [\n",
    "    # 조사\n",
    "    '은', '는', '이', '가', '을', '를', '에', '에서', '에게', '한테', '으로', '로',\n",
    "    '과', '와', '도', '만', '이나', '보다', '처럼', '까지', '부터', '라도', '마저',\n",
    "\n",
    "    # 접속사\n",
    "    '그리고', '그러나', '하지만', '그래서', '그러면', '그런데', '따라서', '혹은', '또는',\n",
    "\n",
    "    # 의존명사/형식적 명사\n",
    "    '수', '것', '거', '때', '중', '등', '뿐', '대로', '만큼', '따위',\n",
    "\n",
    "    # 대명사/지시어\n",
    "    '나', '너', '우리', '저희', '그', '이', '저', '그것', '이것', '저것', '자기',\n",
    "\n",
    "    # 일반 동사/보조용언\n",
    "    '되다', '하다', '있다', '없다', '이다', '아니다', '받다', '주다', '되어다', '같다', '되었다',\n",
    "\n",
    "    # 감탄사/불필요 표현\n",
    "    '아', '야', '어', '우와', '헐', '음', '응', '네', '예', '자', '좀', '요', '그냥', '또', '그래',\n",
    "\n",
    "    # 빈도 높은 불필요 어휘\n",
    "    '정말', '진짜', '너무', '매우', '아주', '항상', '더', '더욱', '계속', '이미', '이제',\n",
    "\n",
    "    # 불용 보조 용언/어미 어절\n",
    "    '것이다', '것이', '때문이다', '있습니다', '없습니다', '하는', '해서', '하였다', '했다', '하고', '하며', '하면서',\n",
    "\n",
    "    # 기타 (프로젝트 목적 따라 제거 가능)\n",
    "    '하지만', '그러나', '혹시', '그러면', '그럼', '혹은', '만약', '만일', '또는'\n",
    "    ]\n",
    "\n",
    "    return [word for word in mecab.morphs(text) if word not in stop_words]\n",
    "\n",
    "data_train = train_df['document'].progress_apply(word_tokenization)\n",
    "display(data_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a927cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52185\n",
      "13727\n",
      "[[879, 187, 21, 663], [925, 449, 296, 593, 2, 89, 1512, 34, 754, 912, 11, 27, 331], [162, 1]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 879\n",
      "  187  21 663]]\n"
     ]
    }
   ],
   "source": [
    "# 지금까지 진행하면... 형태소 분석과 불용어 처리까지 진행할 수 있어요!\n",
    "# 이걸 이용해서 단어사전을 만들 수 있어요!\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_train) # 분리되어 있는 형태소가 결국 Token이 되고\n",
    "                                   # 이 Token들을 이용해서 vocabulary 생성\n",
    "# 총 단어 개수\n",
    "print(len(tokenizer.word_index)) # 52185\n",
    "\n",
    "# 이 5만개의 단어를 다 사용해서 문자열을 숫자 시퀀스로 변경할 건가요?\n",
    "# 일반적으로 많은 빈도를 가지는 형태소(Token)만을 이용해서 문자열을 숫자 시퀀스로 변경\n",
    "# 그럼 몇개가 적당할까요?\n",
    "# print(tokenizer.word_counts)\n",
    "\n",
    "def get_voca_size(threshold):\n",
    "    cnt = 0\n",
    "    for x in tokenizer.word_counts.values():\n",
    "        if x > threshold:\n",
    "            cnt = cnt + 1\n",
    "    return cnt\n",
    "\n",
    "voca_size = get_voca_size(5)\n",
    "print(voca_size)\n",
    "\n",
    "# 단어 사전을 생성할거에요!\n",
    "tokenizer = Tokenizer(oov_token='<OOV>',\n",
    "                      num_words=15000)\n",
    "\n",
    "tokenizer.fit_on_texts(data_train)\n",
    "\n",
    "# 단어 사전을 만들었으니 이걸 이용해서 문자열을 숫자의 시퀀스로 변경할 수 있어요!\n",
    "data_train_seq = tokenizer.texts_to_sequences(data_train)\n",
    "print(data_train_seq[0:3])\n",
    "\n",
    "# 최종적으로 길이만 똑같이 만들어주면 우리 모델에 집어넣을 수 있는 형태가 완성될 것같아요!\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_data_train = pad_sequences(data_train_seq,\n",
    "                             maxlen=75)\n",
    "y_data_train = np.asarray(train_df['label'])\n",
    "\n",
    "# 확인\n",
    "print(x_data_train[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3991fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터는 준비가 끝났으니 이제 모델만 만들어주면 되요!\n",
    "# 데이터 만들 때 one_hot encoding을 하지 않았어요 => Embedding을 사용\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=15001,\n",
    "                    output_dim=128,\n",
    "                    input_length=75))\n",
    "model.add(LSTM(units=16,\n",
    "               activation='tanh'))\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 3가지 callback을 사용!\n",
    "# 이 중 일단 EarlyStopping만 적용\n",
    "es_callback = EarlyStopping(monitor='val_loss',\n",
    "                            patience=5,\n",
    "                            restore_best_weights=True,\n",
    "                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2440e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:51:51.232652: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 13ms/step - accuracy: 0.7948 - loss: 0.4372 - val_accuracy: 0.8516 - val_loss: 0.3416\n",
      "Epoch 2/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.8753 - loss: 0.2898 - val_accuracy: 0.8562 - val_loss: 0.3343\n",
      "Epoch 3/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8999 - loss: 0.2387 - val_accuracy: 0.8543 - val_loss: 0.3479\n",
      "Epoch 4/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.2012 - val_accuracy: 0.8501 - val_loss: 0.3747\n",
      "Epoch 5/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9340 - loss: 0.1649 - val_accuracy: 0.8431 - val_loss: 0.4382\n",
      "Epoch 6/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.9462 - loss: 0.1365 - val_accuracy: 0.8402 - val_loss: 0.4728\n",
      "Epoch 7/100\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9543 - loss: 0.1177 - val_accuracy: 0.8418 - val_loss: 0.5191\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f99aa01e050>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 진행\n",
    "model.fit(x_data_train,\n",
    "          y_data_train,\n",
    "          epochs=100,\n",
    "          batch_size=64,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es_callback],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90a852f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 1315.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "[[0.1093169 ]\n",
      " [0.9931677 ]\n",
      " [0.0079077 ]\n",
      " [0.01173522]\n",
      " [0.9872938 ]\n",
      " [0.01043729]\n",
      " [0.72699064]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝난 다음\n",
    "# 예측작업을 수행할 수 있어요!\n",
    "review_sentences = ['내가 만들어도 이것보다는 잘 만들겠다',\n",
    "                    '너무너무 재미있었어요. 감사합니다.',\n",
    "                    '아...내돈..돈이 너무 아까워요!',\n",
    "                    '이것도 영화라고 쯧쯧.. 스토리가 산으로 가요',\n",
    "                    '감동과 재미가 있는 영화입니다.',\n",
    "                    '너무너무 재미없다.. 잠와 죽는줄',\n",
    "                    '너무너무 재미있다.. 잠이 확깨요']\n",
    "\n",
    "# 이 Review를 모델에 넣어서 예측을 수행\n",
    "# 데이터 전처리를 해야해요!\n",
    "df = pd.DataFrame({'document': review_sentences})\n",
    "\n",
    "# 1. 정규식 이용해서 특수문자 제거(한글, 영어, 공백 제외하고)\n",
    "df['document'] = df['document'].str.replace(r'[^A-Za-z가-힣ㄱ-ㅎㅏ-ㅣ ]',\n",
    "                                            '',\n",
    "                                            regex=True)\n",
    "# 2. 결측치 처리 -> 할게 없어요!\n",
    "# 3. 형태소 분석하고 불용어를 제거\n",
    "data_predict = df['document'].progress_apply(word_tokenization)\n",
    "# 4. 이미 만들어 놓은 vocabulary를 이용해서\n",
    "#    우리 문장을 숫자로 변환\n",
    "data_predict_seq = tokenizer.texts_to_sequences(data_predict)\n",
    "# 5. 숫자로 변환이 됐으니 길이를 맞춰줘요. -> 75개!\n",
    "x_data_predict = pad_sequences(data_predict_seq,\n",
    "                               maxlen=75)\n",
    "\n",
    "result = model.predict(x_data_predict)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
