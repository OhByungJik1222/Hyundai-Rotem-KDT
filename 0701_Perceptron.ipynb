{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10d8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron 구현\n",
    "# AND, OR, XOR에 대한 진리표를 이용해서 구현\n",
    "\n",
    "%reset -f\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Tensorflow Keras 구현에 비해 PyTorch 구현은 Low Level 구현의 분위기\n",
    "# PyTorch Lighting -> Lighting으로 2023에 이름이 바뀌었어요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670eae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Set\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float32)\n",
    "# AND 연산\n",
    "# y_data = np.array([0, 0, 0, 1], dtype=np.float32)\n",
    "# OR 연산\n",
    "# y_data = np.array([0, 1, 1, 1], dtype=np.float32)\n",
    "# XOR 연산\n",
    "y_data = np.array([0, 1, 1, 0], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a05334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn 구현\n",
    "# Logisitic Regression으로 구현\n",
    "\n",
    "# Machine Learning vs Deep Learning\n",
    "# 1. Machine Learning 기법\n",
    "# -> Regression, KNN, SVM, Decision Tree, Random Forest, XGBoost, LightGBM\n",
    "# -> 이미 구현된 구현체가 있어요!\n",
    "# -> 이 기법의 Hyperparameter 수정 + 수작업 Feature Engineering을 진행\n",
    "# 2. Deep Learning 기법\n",
    "# -> 당연히 Hyperparameter 수정 + Feature Engineering + 알파\n",
    "\n",
    "# 규제에 대한 Hyperparameter 수정으로 성능을 높여준다\n",
    "sklearn_model = linear_model.LogisticRegression(C=100)\n",
    "\n",
    "sklearn_model.fit(x_data,\n",
    "                  y_data)\n",
    "\n",
    "y_pred = sklearn_model.predict(x_data)\n",
    "print(accuracy_score(y_data, y_pred))\n",
    "# 1.0 -> LogisticRegression(Perceptron)은 AND, OR 연산에 대한 학습이 잘 되는군요!\n",
    "# 0.5 -> LogisticRegression(Perceptron)은 XOR 연산에 대한 학습이 안되요! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/obj/anaconda3/envs/llm_env/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(2,)))\n",
    "keras_model.add(Dense(units=1,\n",
    "                      activation='sigmoid'))\n",
    "\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# tensorboard를 이용해서 학습이 진행될 때 상태를 기록해 보아요!\n",
    "# 파일로 기록하는거기 때문에 어디에 기록할지 명시를 해야해요!\n",
    "# cd jupyter_home -> tensorboard --logdir=logs\n",
    "log_dir = './logs/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tb_callback = TensorBoard(log_dir=log_dir,\n",
    "                          histogram_freq=1)\n",
    "\n",
    "keras_model.fit(x_data,\n",
    "                y_data,\n",
    "                epochs=500,\n",
    "                verbose=0,\n",
    "                callbacks=[tb_callback])\n",
    "\n",
    "keras_y_pred = keras_model.predict(x_data)\n",
    "# 이렇게 하면 확률값이 나와요! 0,0 -> 확률, 0,1 -> 확률 ...\n",
    "keras_y_pred_class = (keras_y_pred >= 0.5).astype(int)\n",
    "# ex) keras_y_pred = [0.7 0.5 0.3 0.5] -> [1. 1. 0. 1.] Broadcasting\n",
    "print(accuracy_score(y_data, keras_y_pred_class)) # 0.5 -> 여전히 XOR 연산은 학습이 안되요!\n",
    "# Single Layer Perceptron -> X\n",
    "# Multi Layer Perceptron(MLP)는 가능해요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08732204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47 0.32999999999999996\n",
      "0.615 0.582\n",
      "0.60015\n",
      "0.646\n",
      "0.125\n"
     ]
    }
   ],
   "source": [
    "# 1. 순전파(Feed Forward) 과정 (강의 자료 참고)\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x1 = 0.5\n",
    "x2 = 0.3\n",
    "\n",
    "w1 = 0.7\n",
    "w2 = 0.3\n",
    "w3 = 0.4\n",
    "w4 = 0.6\n",
    "\n",
    "z1 = x1 * w1 + x2 * w3\n",
    "z2 = x1 * w2 + x2 * w4\n",
    "print(z1, z2) # 0.47 0.33\n",
    "\n",
    "h1 = round(sigmoid(z1), 3)\n",
    "h2 = round(sigmoid(z2), 3)\n",
    "print(h1, h2) # 0.615 0.582\n",
    "\n",
    "w5 = 0.55\n",
    "w6 = 0.45\n",
    "\n",
    "z3 = h1 * w5 + h2 * w6\n",
    "print(z3) # 0.6\n",
    "\n",
    "o1 = round(sigmoid(z3), 3)\n",
    "print(o1) # 0.646\n",
    "\n",
    "# 2. Loss 계산 -> MSE\n",
    "loss = round(np.power(1 - o1, 2), 3) # 정답이 1이라면\n",
    "print(loss) # 0.125\n",
    "\n",
    "# 3. w 값 update\n",
    "# -> 직접 편미분 (x) 시간이 오래걸림\n",
    "# -> 역전파 (o) Chain Rule 이용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
