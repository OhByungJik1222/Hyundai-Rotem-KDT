{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15e6188-f53b-4900-875a-adcfbee1a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "# tf.data\n",
    "# Tensorflow에서 데이터 전용 처리 함수 & 클래스가 모여있는 package\n",
    "# 대용량의 데이터를 처리할 때, 이런 데이터를 머신러닝의 입력으로 사용할 때\n",
    "# 해당 package 안의 함수와 class를 이용하면 좋아요!\n",
    "\n",
    "# tf.data package안에 있는 여러개의 함수와 class 중 \n",
    "# 가장 중요한 class는 Dataset이에요!\n",
    "# => 여러개의 데이터를 읽어들이는 파이프라인 객체를 생성하기 위해 사용해요!\n",
    "# Dataset 자체가 Data를 가지고 있는데 아니에요!\n",
    "# 데이터를 가져오는 방법과 규칙을 정의하는 class에요!\n",
    "\n",
    "# Dataset에 대해서 알아보기 전에\n",
    "# 먼저 tf.Tensor라는 것에 대해서 먼저 알아야 해요!\n",
    "# tf.Tensor는 Tensorflow에서 데이터를 표현하는 가장 기본적인 자료구조.\n",
    "# 지금까지 외부데이터를 ndarray로 만들어서 Tensorflow Model에 입력으로\n",
    "# 넣었어요! 그러면 Tensorflow Model 내에서는 이 데이터가 Tensor로 변환되서 사용되요!\n",
    "\n",
    "# 그럼 numpy의 ndarray를 기반으로 pandas의 DataFrame을 만들어서 사용했듯이\n",
    "# numpy의 ndarray를 기반으로 tf.Tensor를 만들어서 사용하는 건가요?\n",
    "# 아니에요! 두개는 완전히 다른거에요! 단, 서로 변환은 가능해요!\n",
    "\n",
    "# tf.Tensor\n",
    "# 1. 다차원 배열\n",
    "# 2. 데이터 타입도 존재 (np.float32 => tf.float32)\n",
    "# 3. 행렬연산을 지원(np.add() => tf.add())\n",
    "# 4. GPU 메모리 지원(반대로 ndarray는 CPU 메모리만 사용가능)\n",
    "# 5. ndarray로 변환하려면 어떻게 해야하나요 => .numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be67b8e3-c337-4942-a57c-7a3432c6a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "[1 2 3]\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0.7598582  -0.7730717  -0.53677905]\n",
      " [-0.22217543 -0.7422878  -0.4758832 ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.Tensor를 생성하는 방법\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 1차원 Tensor 생성\n",
    "# np.array([1, 2, 3])\n",
    "tensor1 = tf.constant([1, 2, 3])\n",
    "print(tensor1) # tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
    "print(tensor1.numpy()) # [1 2 3]\n",
    "\n",
    "# 2차원 Tensor 생성\n",
    "tensor2 = tf.constant([[1, 2], [3, 4]])\n",
    "print(tensor2)\n",
    "# tf.Tensor(\n",
    "# [[1 2]\n",
    "#  [3 4]], shape=(2, 2), dtype=int32)\n",
    "\n",
    "# tf.zeros()\n",
    "tensor3 = tf.zeros([2,3])\n",
    "print(tensor3)\n",
    "# tf.Tensor(\n",
    "# [[0. 0. 0.]\n",
    "#  [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
    "\n",
    "# tf.range()\n",
    "tensor4 = tf.range(0, 10, 2)\n",
    "print(tensor4) # tf.Tensor([0 2 4 6 8], shape=(5,), dtype=int32)\n",
    "\n",
    "# tf.random.normal() (표준정규분포)\n",
    "tensor5 = tf.random.normal([2,3])\n",
    "print(tensor5)\n",
    "# tf.Tensor(\n",
    "# [[ 0.7598582  -0.7730717  -0.53677905]\n",
    "#  [-0.22217543 -0.7422878  -0.4758832 ]], shape=(2, 3), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "269e797b-0cd7-4a6c-9e3c-ebaeb7fb3d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6  8]\n",
      " [10 12]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Tensor의 연산\n",
    "a = tf.constant([[1, 2], \n",
    "                 [3, 4]])\n",
    "b = tf.constant([[5, 6], \n",
    "                 [7, 8]])\n",
    "\n",
    "# print(a + b)\n",
    "print(tf.add(a, b))\n",
    "# tf.Tensor(\n",
    "# [[ 6  8]\n",
    "#  [10 12]], shape=(2, 2), dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e482e92a-6283-4f5f-a82f-6a0c56adf53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([10., 20., 30.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# tf.constant() Tensor를 만들면 read only에요!\n",
    "# 이렇게 Tensor를 만들면 상수로 만들어져요!\n",
    "\n",
    "# 그러면 변수처럼 값을 변화시킬 수 있은 Tensor는 어떻게 만드나요?\n",
    "# Tensorflow에서는 tf.Variable로 제공해요!\n",
    "a = tf.Variable([1.0, 2.0, 3.0])\n",
    "print(a)\n",
    "\n",
    "a.assign([10, 20, 30])\n",
    "print(a)\n",
    "\n",
    "# Tensorflow Model 안에 들어가는 데이터는 tf.Tensor로 만들어져서 사용!\n",
    "# Tensorflow Model 안에 W, b, filter.. 이런 변하는 변수는 당연히\n",
    "# tf.Variable 로 만들어져서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "902e321e-73fc-4479-9daf-dce8c7152776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.data.Dataset\n",
    "# Dataset 생성에는 총 5가지 방법이 있어요!\n",
    "\n",
    "# 1. from_tensor_slices()\n",
    "# 입력 데이터의 첫번째 차원을 따라서\n",
    "# 각 원소별로 하나의 샘플을 만들어\n",
    "# tf.Tensor로 감싸진 Dataset을 생성해요!\n",
    "# => 쉽게 말하면, 각원소를 하나의 데이터 샘플로 만들어서\n",
    "# => 이 데이터 전체를 하나의 Dataset으로 래핑하는 거에요!\n",
    "# list 혹은 ndarray안의 요소들을 조각내서\n",
    "# 각 요소를 Tensor로 만들어 차례로 반환하는 Dataset 객체를 생성\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "dataset = tf.data.Dataset.from_tensor_slices(my_list)\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dadcf2a-8fd8-4c33-99e7-ff3d24590788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 4.], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([5., 6.], dtype=float32)>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1.0, 2.0], \n",
    "          [3.0, 4.0], \n",
    "          [5.0, 6.0]]\n",
    "t_data = [0, 1, 0]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_data, t_data))\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7594db78-2533-4772-9094-6b80fc971b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 2. from_tensors()\n",
    "# 여러 개의 sample이 아니라 전체를 하나의 tensor로 만들어요!\n",
    "# 즉, 데이터 1개짜리 Dataset을 만드는 거에요!\n",
    "# 특성 상 많이 사용되지는 않아요. 기본적인 사용에 제한이 있어요!\n",
    "# 대신 어떤 특수한 상황에서는 사용하기도 해요!\n",
    "# 작은 데이터 셋을 만들어서 test용으로 사용할 경우\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensors(my_list)\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ebce425-4f20-4831-8f49-d5a0a5157a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 3. from_generator()\n",
    "# Python의 generator 함수를 이용해서\n",
    "# 이 generator 함수가 생산하는 값을 Tensor로 만들어서 사용하는\n",
    "# Dataset을 만드는 함수\n",
    "# 여러이유로 유용하기 때문에 많이 사용\n",
    "# 대용량의 데이터를 처리하기가 용이\n",
    "# 데이터를 증강시키기 위해서 사용.\n",
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7cc9571-0835-420c-aa74-f1918bcac7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4 3], shape=(2,), dtype=int32)\n",
      "tf.Tensor([6 4], shape=(2,), dtype=int32)\n",
      "tf.Tensor([8 5], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield (i*2, i+1)\n",
    "        # (0, 1)\n",
    "        # (2, 2)\n",
    "        # (4, 3) ...\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(2,),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84d2445b-3459-4b13-9348-40c8e227317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=4>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=6>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=int32, numpy=8>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield (i*2, i+1)\n",
    "        # (0, 1)\n",
    "        # (2, 2)\n",
    "        # (4, 3) ...\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=(tf.TensorSpec(shape=(),\n",
    "                                    dtype=tf.int32),\n",
    "                      tf.TensorSpec(shape=(),\n",
    "                                    dtype=tf.int32))\n",
    ")\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23342bd5-e53b-4a35-8bec-877b24f8e13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'./data/cat_dog_small/train/cats/cat.915.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'./data/cat_dog_small/train/cats/cat.519.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'./data/cat_dog_small/train/cats/cat.929.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'./data/cat_dog_small/train/cats/cat.555.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'./data/cat_dog_small/train/cats/cat.34.jpg', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 4. list_files()\n",
    "# Dataset을 만드는 함수\n",
    "# 파일 경로 목록을 Dataset으로 만들어요!\n",
    "\n",
    "dataset = tf.data.Dataset.list_files('./data/cat_dog_small/train/cats/*.jpg')\n",
    "\n",
    "i = 0\n",
    "for data in dataset:\n",
    "    print(data)\n",
    "    i += 1\n",
    "    if i % 5 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e360b6b-a071-4d15-85eb-0fa474bb8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. TFRecordDataset()\n",
    "# 특수한 목적으로 만들어진 파일을 불러들여서 \n",
    "# Dataset을 만들때 사용하는 함수에요!\n",
    "# TFRecord : Tensorflow에서 사용하는 표준 데이터 포맷."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "682ee88b-febd-4f7c-81cd-982319544f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 총 5개의 방법으로 Dataset을 생성할 수 있어요!\n",
    "# Data source로부터 다양한 방법으로 데이터를 읽어들여 \n",
    "# Tensor로 변환해서 데이터를 제공하는 객체\n",
    "# from_tensor_slices()\n",
    "# from_tensors()\n",
    "# from_generator()\n",
    "# list_files()\n",
    "# TFRecordDataset()\n",
    "# ...\n",
    "\n",
    "# 결국 Data source로부터 Tensor를 얻었어요!\n",
    "# Dataset은 파이프라인이에요!\n",
    "# 기능적으로 여러가지를 얻은 Tensor에 적용할 수 있어요!\n",
    "# 어떤 작업을 더 할 수 있나요?\n",
    "# 그 작업을 하기 위해서 어떻게 해야 하나요?\n",
    "# 정해져 있는 함수가 있어요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb718f1a-99e2-4413-bc07-042e5b26dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4 4], shape=(2,), dtype=int32)\n",
      "tf.Tensor([16  9], shape=(2,), dtype=int32)\n",
      "tf.Tensor([36 16], shape=(2,), dtype=int32)\n",
      "tf.Tensor([64 25], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "# Dataset이 가지고 있는 함수들에 대해서 알아보아요!\n",
    "\n",
    "# 1. map() : 별도의 함수를 Tensor에 적용해서 Tensor를 변화시킬 수 있어요!\n",
    "# 가장 대표적인 함수가 map()\n",
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2, i + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(2,),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "def my_func(x):\n",
    "    return x * x\n",
    "\n",
    "dataset = dataset.map(my_func,\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "224962f8-89cf-4e5b-933f-3aafdeaecad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 2], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor([8], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 2. batch() : 몇개씩 묶어서 하나의 mini-batch를 만들어요!\n",
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "dataset = dataset.batch(2)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8dac57a-f981-4c05-bbe8-cd834244b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1]\n",
      " [2 2]\n",
      " [4 3]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6 4]\n",
      " [8 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2, i + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(2,),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "dataset = dataset.batch(3)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93c167bc-408c-4ba0-9e3d-4eeec56920d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0  1]\n",
      " [ 4  4]\n",
      " [16  9]], shape=(3, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[36 16]\n",
      " [64 25]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2, i + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(2,),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "def my_func(x):\n",
    "    return x * x\n",
    "\n",
    "dataset = dataset.map(my_func).batch(3)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76f09db4-ef87-41f3-aaac-bca365750b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 3. shuffle()\n",
    "# 데이터의 순서를 섞을 때 사용(학습용 데이터는 섞어주는게 더 학습이 잘되요!)\n",
    "# vlaidation하거나 test할 때는 데이터를 섞지 않아요!\n",
    "# buffer_size를 명시해야 해요! \n",
    "# buffer_size는 Dataset의 크기만큼 잡아주는게 좋아요!\n",
    "# 데이터 크기만큼 설정하기 힘들 수도 있어요!\n",
    "# 이런 경우에는 1000 정도로 설정\n",
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=5)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de0f4ad4-1398-42ab-8d5a-e2665950998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 4. repeat()\n",
    "# 반복해서 데이터를 추출\n",
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "dataset = dataset.repeat(2)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "eda37ce6-8b02-40f0-b16e-7b8490b8d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 5. prefetch()\n",
    "# GPU 학습과 CPU 데이터 준비를 병렬로 처리하도록 해요.\n",
    "# 학습의 속도를 굉장히 많이 높여줘요!\n",
    "# buffer_size 값은 tf.data.AUTOTUNE으로 설정\n",
    "def gen():\n",
    "    for i in range(5):\n",
    "        yield i * 2\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    output_signature=tf.TensorSpec(shape=(),\n",
    "                                   dtype=tf.int32)\n",
    ")\n",
    "\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "56811504-3c06-4545-9ae1-fc429ab9654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. cache()\n",
    "# 디스크에서 읽은 데이터를 메모리에 cache시켜놓고\n",
    "# 다음번 사용할 때 cache에 있는 데이터를 사용하는 개념.\n",
    "# 학습의 속도가 굉장히 빨라져요!\n",
    "# 일단 메모리량에 따라서 달라질 수 있어요!\n",
    "# 데이터가 epoch마다 변화해야하는 경우에는 cache사용에 주의\n",
    "# Augmentation이 적용 안될 수 있어요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b13e42d9-7fa0-43e1-ac3c-5ba405a0f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과적으로\n",
    "# dataset은 5가지 방법으로 생성할 수 있구요!\n",
    "# 6개의 함수를 이용해서 dataset을 활용할 수 있어요!\n",
    "# map() : 여러 번 나올 수 있어요!\n",
    "# batch()\n",
    "# shuffle()\n",
    "# repeat()\n",
    "# prefetch()\n",
    "# cache() : 데이터의 흐름에서 가장 먼저 호출되요!\n",
    "#           map() 까지 적용시킨 후\n",
    "#           cache(), shuffle(), batch(), prefetch() 순서\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "140eb2e0-5aea-4008-a04d-70c03a02c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([14  6], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 2 16], shape=(2,), dtype=int32)\n",
      "tf.Tensor([10 12], shape=(2,), dtype=int32)\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 배운 내용을 적용해보아요!\n",
    "my_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(my_list)\n",
    "\n",
    "dataset = (dataset.map(lambda x : x * 2,\n",
    "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                  .cache()\n",
    "                  .shuffle(buffer_size=8)\n",
    "                  .batch(2)\n",
    "                  .prefetch(buffer_size=9))\n",
    "\n",
    "for data in dataset:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff19a05-9f74-4d9d-8da8-de280d0a7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기까지 tf.data.Dataset에 대해서 알아보았어요!\n",
    "# tf.Tensor부터 시작해서 여러 함수들에 대해서 살펴보았는데..\n",
    "# 이제 MNIST 예제를 이용해서 ndarray를 이용하지 않고 Dataset을 이용해서\n",
    "# 우리 model의 입력을 처리해보아요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "01180c0a-6360-43c2-a2c5-047a95e17230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tf.data.Dataset 자체에는 class 비율에 맞게 분리해주는 기능은 따로 없어요!\n",
    "# 초기에 CSV 파일을 읽어서 sklearn이 가지고 있는 기능을 이용해서\n",
    "# 데이터를 분리한 다음 Dataset으로 변환\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/mnist/train.csv')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e4fbc6e-e103-4eb3-8b4b-9a21529908e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터의 수 : 26880\n",
      "val 데이터의 수 : 6720\n",
      "test 데이터의 수 : 8400\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False).values\n",
    "t_data = df['label'].values\n",
    "\n",
    "x_data_train, x_data_test, t_data_train, t_data_test = \\\n",
    "train_test_split(x_data,\n",
    "                 t_data,\n",
    "                 test_size=0.2,\n",
    "                 stratify=t_data,\n",
    "                 random_state=42)\n",
    "x_data_train, x_data_val, t_data_train, t_data_val = \\\n",
    "train_test_split(x_data_train,\n",
    "                 t_data_train,\n",
    "                 test_size=0.2,\n",
    "                 stratify=t_data_train,\n",
    "                 random_state=42)\n",
    "print(f'train 데이터의 수 : {len(x_data_train)}')\n",
    "print(f'val 데이터의 수 : {len(x_data_val)}')\n",
    "print(f'test 데이터의 수 : {len(x_data_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8aaf92e2-f31d-4a56-a739-2002372616e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 생성(3개 만들어야 해요. train, validation, test)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def make_dataset(x, t, train=False):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, t))\n",
    "    dataset = dataset.map(lambda x, t : (tf.cast(x, tf.float32)/255.0, t),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE) # 정규화\n",
    "    dataset.cache()\n",
    "    if train:\n",
    "        dataset = dataset.shuffle(buffer_size=len(x))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(x_data_train,\n",
    "                             t_data_train,\n",
    "                             train=True)\n",
    "val_dataset = make_dataset(x_data_val,\n",
    "                           t_data_val,\n",
    "                           train=True)\n",
    "test_dataset = make_dataset(x_data_test,\n",
    "                            t_data_test,\n",
    "                            train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1f72de5a-61eb-43cf-b389-8d12ed51bced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 64)                256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60618 (236.79 KB)\n",
      "Trainable params: 60234 (235.29 KB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 구성\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "inputs = Input(shape=(784,))\n",
    "x = Flatten()(inputs)\n",
    "x = Dense(units=64)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "x = Dense(units=128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "x = Dense(units=10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331749d5-1821-48f8-bbe2-f9b14a782e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_dataset,\n",
    "          epochs=10,\n",
    "          validation_data=val_dataset,\n",
    "          verbose=1)\n",
    "# Epoch 10/10\n",
    "# 840/840 [==============================] - 19s 22ms/step - \n",
    "# loss: 0.1849 - accuracy: 0.9409 - val_loss: 0.1246 - val_accuracy: 0.9598"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
