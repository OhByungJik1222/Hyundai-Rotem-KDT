{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d6d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 구현\n",
    "# Tensorflow 구현\n",
    "# PyTorch 구현\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime # 날짜 관련된 module, TensorBoard에서 이용한 로그를 저장할\n",
    "                # 폴더명을 만들기 위해서 사용.\n",
    "\n",
    "# 정규화를 편하게 하기 위해서\n",
    "# 정규화 기법은 크게 2가지만 알아두면 되요!\n",
    "# MinMaxScaler : 0 ~ 1 사이로 scaling -> 딥러닝 학습에 유리\n",
    "# StandardScaler : 데이터의 분포를 유지하면서 값을 정규화, -3 ~ 3\n",
    "# 일반적인 경우(머신러닝같은 경우)에는 표준화를 이용해서 정규화하는게 좋아요! \n",
    "# 딥러닝같은 경우 합습을 안정적으로 하기 위해 MinMaxScaler를 이용해서 정규화.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340f4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 로딩과 전처리\n",
    "df = pd.read_csv('./data/mnist/train.csv')\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72a572d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600\n"
     ]
    }
   ],
   "source": [
    "# 결측치와 이상치는 없어요!\n",
    "# 데이터를 분리\n",
    "x_data = df.drop('label', axis=1, inplace=False).values # 2차원 ndarray\n",
    "y_data = df['label'].values # 1차원 ndarray\n",
    "\n",
    "# 학습데이터와 테스트데이터를 분리\n",
    "x_data_train, x_data_test, y_data_train, y_data_test = \\\n",
    "train_test_split(x_data,\n",
    "                 y_data,\n",
    "                 test_size=0.2,\n",
    "                 stratify=y_data,\n",
    "                 random_state=42)\n",
    "\n",
    "# 정규화\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_x.fit(x_data_train)\n",
    "\n",
    "x_data_train_norm = scaler_x.transform(x_data_train)\n",
    "x_data_test_norm = scaler_x.transform(x_data_test)\n",
    "\n",
    "print(len(x_data_train_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ec780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 구현\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(784,)))\n",
    "keras_model.add(Dense(units=128,\n",
    "                      activation='relu'))\n",
    "keras_model.add(Dense(units=64,\n",
    "                      activation='relu'))\n",
    "keras_model.add(Dense(units=10,\n",
    "                      activation='softmax'))\n",
    "\n",
    "# 모델 설정\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Callback 설정\n",
    "es_callback = EarlyStopping(monitor='val_loss',\n",
    "                            patience=4,\n",
    "                            restore_best_weights=True,\n",
    "                            verbose=1)\n",
    "# 저장하기 위한 ModelCheckpoint\n",
    "# TensorBoard\n",
    "log_dir = './logs/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tb_callback = TensorBoard(log_dir=log_dir,\n",
    "                          histogram_freq=1)\n",
    "\n",
    "# 모델 학습\n",
    "keras_model.fit(x_data_train_norm,\n",
    "                y_data_train,\n",
    "                epochs=100,\n",
    "                validation_split=0.2,\n",
    "                callbacks=[es_callback, tb_callback],\n",
    "                verbose=1,\n",
    "                batch_size=32)\n",
    "# Epoch 10/100\n",
    "# 840/840 ━━━━━━━━━━━━━━━━━━━━ 4s 4ms/step \n",
    "# - accuracy: 0.9955 - loss: 0.0148 - val_accuracy: 0.9674 - val_loss: 0.1397\n",
    "# Epoch 10: early stopping\n",
    "# Restoring model weights from the end of the best epoch: 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfbbd330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 구현\n",
    "# Tensorflow 같은 경우 GPU설정(CUDA, cuDNN 설정)을 했다면 자동으로 GPU를 사용해서\n",
    "# 학습을 진행!\n",
    "# 하지만 PyTorch는 그렇지 않아요!\n",
    "# 명시적으로 사용하는 Model과 Data를 GPU에 올려줘야 해요!\n",
    "# PyTorch Lighting => GPU 설정이 되어 있다면 GPU에서 실행!\n",
    "import torch\n",
    "import torch.nn as nn # Layer\n",
    "import torch.optim as optim # Optimizer\n",
    "from torch.utils.tensorboard import SummaryWriter # TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82d707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU를 사용할 수 있는지를 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2900748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs : 0/10000\n",
      "Epochs : 1000/10000\n",
      "Epochs : 2000/10000\n",
      "Epochs : 3000/10000\n",
      "Epochs : 4000/10000\n",
      "Epochs : 5000/10000\n",
      "Epochs : 6000/10000\n",
      "Epochs : 7000/10000\n",
      "Epochs : 8000/10000\n",
      "Epochs : 9000/10000\n"
     ]
    }
   ],
   "source": [
    "# TensorBoard를 위한 로그 파일\n",
    "log_dir = './logs/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# 데이터 변환\n",
    "# 기존에 가지고 있던 ndarray를 PyTorch의 tensor로 변환\n",
    "x_tensor_train = torch.FloatTensor(x_data_train_norm).to(device)\n",
    "x_tensor_test = torch.FloatTensor(x_data_test_norm).to(device)\n",
    "\n",
    "y_tensor_train = torch.LongTensor(y_data_train).to(device)\n",
    "y_tensor_test = torch.LongTensor(y_data_test).to(device)\n",
    "\n",
    "# Model을 만들어야 해요!\n",
    "# Tensorflow같은 경우 Sequential 같은 것들을 이용해서 생성.\n",
    "# PyTorch는 class를 생성해야 해요!\n",
    "# 즉, 모델의 기능을 class로 정의한 후,\n",
    "# class로부터 객체를 생성 => 우리의 모델 객체가 있어요!\n",
    "# class는 모델의 기능을 설명!\n",
    "# class의 instance(객체)가 실제 동작하는 모델이에요!\n",
    "class MNISTModule(nn.Module): # nn.Module 클래스를 상속(inheritence)해서 우리 클래스를 정의해요!\n",
    "    def __init__(self):       # class로부터 모델 객체가 생성될 때 자동으로 호출!\n",
    "        super().__init__()    # 상위 클래스의 생성자를 호출해서 초기화를 진행!\n",
    "        # 그 다음에는 우리 모델객체가 가지고 있는 Layer를 속성(변수)으로 명시\n",
    "        self.hidden1 = nn.Linear(784, 128) # Tensorflow의 Dense Layer (입력과 출력을 동시에 명시)\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(64, 10)\n",
    "\n",
    "    # 중요한 함수가 하나 나와요. 이 함수는 overriding 함수에요!\n",
    "    # 순전파 기능을 하는 함수.\n",
    "    def forward(self, x):\n",
    "        # 위쪽에 명시해 놓은 Layer를 이용해서 순전파를 진행시키면 되요!\n",
    "        # 우리 모델의 예측값을 return하면 되요!\n",
    "        x = self.hidden1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.output(x)\n",
    "        # softmax activation 처리는 여기서 하지 않아요!\n",
    "        return x\n",
    "    \n",
    "# Model 객체 생성\n",
    "torch_model = MNISTModule().to(device) # Model도 GPU에 올려야해요!\n",
    "\n",
    "# Model을 만들었으니 나머지 설정에 관련된 것들을 만들어야 해요!\n",
    "# Loss 지정\n",
    "criterion = nn.CrossEntropyLoss() # Tensorflow에서 'categorical_crossentropy'\n",
    "optimizer = optim.Adam(torch_model.parameters(), # 모델이 가지고 있는 weight\n",
    "                       lr=1e-4)\n",
    "\n",
    "# Model 학습\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    torch_model.train() # Model 학습을 진행하겠다는 의미\n",
    "                        # 이걸 해줘야 나중에 역전파를 위한 내부 그래프를 생성\n",
    "    y_pred = torch_model(x_tensor_train) # 순전파를 진행해서 모델의 예측값을 도출\n",
    "    loss = criterion(y_pred, y_tensor_train) # loss를 계산(숫자값을 계산 + 자료구조도 포함되요)\n",
    "\n",
    "    # optimizer를 통해서 나중에 수정된 w값을 계산해야 해요!\n",
    "    optimizer.zero_grad() # 가지고 있는 gradient를 0으로 초기화.\n",
    "    loss.backward()       # 역전파를 진행(gradient만 계산해서 모든 가중치에 대한 gradient를 전파)\n",
    "    optimizer.step()      # 역전파를 통해 update된 기울기를 이용해서 가중치를 수정!\n",
    "    writer.add_scalar('Loss/train', loss.item(), epoch) # Log 파일에 기록!\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epochs : {epoch}/{epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5f57f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639285714285715\n"
     ]
    }
   ],
   "source": [
    "# 학습이 다 끝나면 평가를 진행\n",
    "torch_model.eval() # 모델안에 있는 Dropout이나 BatchNormalization을 적용하지 않아요\n",
    "with torch.no_grad(): # 속도를 높이기 위해서\n",
    "    torch_y_pred = torch_model(x_tensor_test)\n",
    "    # 확률값으로 나오니까 이 중 가장 높은 확률을 가지는 index가 숫자 이미지에요!\n",
    "    torch_y_pred_class = torch.argmax(torch_y_pred, dim=1).cpu().numpy()\n",
    "    result_accuracy = accuracy_score(y_tensor_test.cpu(), torch_y_pred_class)\n",
    "    print(result_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
